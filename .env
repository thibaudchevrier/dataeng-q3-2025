# ==========================================
# CREDENTIALS - Single Source of Truth
# ==========================================
# This file centralizes all credentials for the data pipeline.
# Docker Compose reads these variables automatically.
# 
# ⚠️  SECURITY NOTICE:
# - DO NOT commit this file with real credentials to version control
# - Add .env to .gitignore
# - For production, use secrets management (Vault, AWS Secrets Manager, etc.)
# - These are development/demo credentials only

# ==========================================
# PostgreSQL Database
# ==========================================
POSTGRES_USER=qonto
POSTGRES_PASSWORD=qonto_password
POSTGRES_DB=transactions
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Database URL (used by applications)
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# ==========================================
# MinIO (S3-Compatible Object Storage)
# ==========================================
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_HOST=minio
MINIO_PORT=9000
MINIO_CONSOLE_PORT=9001
MINIO_BUCKET=transactions

# MinIO endpoint URL (used by applications)
MINIO_ENDPOINT_URL=http://${MINIO_HOST}:${MINIO_PORT}

# ==========================================
# Apache Airflow
# ==========================================
AIRFLOW_UID=50000
AIRFLOW_GID=0

# Airflow Admin User
AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_ADMIN_FIRSTNAME=Admin
AIRFLOW_ADMIN_LASTNAME=User
AIRFLOW_ADMIN_EMAIL=admin@example.com

# Airflow Configuration
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True

# ==========================================
# Kafka Configuration
# ==========================================
KAFKA_BOOTSTRAP_SERVERS=kafka:19092
KAFKA_TOPIC=transactions
KAFKA_DLQ_TOPIC=failed-transactions
KAFKA_CONSUMER_GROUP=transaction-consumer-group

# ==========================================
# ML API Service
# ==========================================
ML_API_HOST=ml-api
ML_API_PORT=8000
ML_API_URL=http://${ML_API_HOST}:${ML_API_PORT}

# ==========================================
# Application Configuration
# ==========================================
# Batch Processing
BATCH_ROW_BATCH_SIZE=5000
BATCH_API_BATCH_SIZE=100
BATCH_API_MAX_WORKERS=5
BATCH_DB_ROW_BATCH_SIZE=1000

# Streaming Processing
STREAMING_MESSAGE_BATCH_SIZE=50
STREAMING_API_BATCH_SIZE=10
STREAMING_API_MAX_WORKERS=5
STREAMING_DB_ROW_BATCH_SIZE=50
STREAMING_BUFFER_TIMEOUT=5.0

# Streaming Producer 1 Configuration
PRODUCER_1_INTERVAL=0.5
PRODUCER_1_MIN_RECORDS=1
PRODUCER_1_MAX_RECORDS=10
PRODUCER_1_RUN_ID=streaming-producer-1

# Streaming Producer 2 Configuration
PRODUCER_2_INTERVAL=1.0
PRODUCER_2_MIN_RECORDS=5
PRODUCER_2_MAX_RECORDS=20
PRODUCER_2_RUN_ID=streaming-producer-2
